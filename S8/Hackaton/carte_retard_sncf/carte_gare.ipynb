{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIX EN PROVENCE TGV', 'ANGERS SAINT LAUD', 'ANGOULEME', 'ANNECY', 'ARRAS', 'AVIGNON TGV', 'BELLEGARDE (AIN)', 'BESANCON FRANCHE COMTE TGV', 'BORDEAUX ST JEAN', 'BREST', 'CHAMBERY CHALLES LES EAUX', 'DIJON VILLE', 'DOUAI', 'DUNKERQUE', 'GRENOBLE', 'LA ROCHELLE VILLE', 'LAVAL', 'LE CREUSOT MONTCEAU MONTCHANIN', 'LE MANS', 'LILLE', 'LYON PART DIEU', 'MACON LOCHE', 'MARNE LA VALLEE', 'MARSEILLE ST CHARLES', 'METZ', 'MONTPELLIER', 'MULHOUSE VILLE', 'NANCY', 'NANTES', 'NICE VILLE', 'NIMES', 'PARIS EST', 'PARIS LYON', 'PARIS MONTPARNASSE', 'PARIS NORD', 'PARIS VAUGIRARD', 'PERPIGNAN', 'POITIERS', 'QUIMPER', 'REIMS', 'RENNES', 'SAINT ETIENNE CHATEAUCREUX', 'ST MALO', 'ST PIERRE DES CORPS', 'STRASBOURG', 'TOULON', 'TOULOUSE MATABIAU', 'TOURCOING', 'TOURS', 'VALENCE ALIXAN TGV', 'VANNES'] 51\n"
     ]
    }
   ],
   "source": [
    "def create_list_station():\n",
    "    df = pd.read_csv('./dataset/regularite-mensuelle-tgv-aqst.csv',sep=\";\")\n",
    "    list_station=[]\n",
    "\n",
    "    for x in df[\"Gare de départ\"]:\n",
    "        if(x not in list_station):\n",
    "            list_station.append(x)\n",
    "\n",
    "    for x in df[\"Gare d'arrivée\"]:\n",
    "        if(x not in list_station):\n",
    "            list_station.append(x)\n",
    "\n",
    "    list_station.sort()\n",
    "\n",
    "    list_station.remove(\"GENEVE\")\n",
    "    list_station.remove(\"FRANCFORT\")\n",
    "    list_station.remove(\"MADRID\")\n",
    "    list_station.remove(\"LAUSANNE\")\n",
    "    list_station.remove(\"STUTTGART\")\n",
    "    list_station.remove(\"ZURICH\")\n",
    "    list_station.remove(\"BARCELONA\")\n",
    "    list_station.remove(\"ITALIE\")\n",
    "\n",
    "\n",
    "    return list_station\n",
    "\n",
    "list_station = create_list_station()\n",
    "\n",
    "print(list_station,len(list_station))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BORDEAUX ST JEAN': [36, 11, 10, 34], 'LA ROCHELLE VILLE': [18, 8, 8, 34], 'PARIS MONTPARNASSE': [27, 10, 15, 29], 'QUIMPER': [20, 20, 9, 42], 'RENNES': [42, 11, 11, 35], 'ST PIERRE DES CORPS': [47, 6, 12, 20], 'TOURS': [18, 6, 14, 19], 'NANTES': [34, 12, 11, 38], 'PARIS EST': [32, 10, 14, 28], 'STRASBOURG': [51, 7, 8, 39], 'DUNKERQUE': [4, 12, 11, 34], 'LILLE': [36, 8, 17, 33], 'TOURCOING': [15, 14, 15, 40], 'CHAMBERY CHALLES LES EAUX': [64, 12, 15, 35], 'LYON PART DIEU': [58, 9, 13, 35], 'MONTPELLIER': [46, 11, 15, 38], 'MULHOUSE VILLE': [50, 6, 11, 37], 'NICE VILLE': [31, 9, 13, 48], 'PARIS LYON': [19, 14, 14, 37], 'BREST': [19, 16, 8, 44], 'POITIERS': [40, 9, 10, 25], 'TOULOUSE MATABIAU': [22, 15, 13, 47], 'REIMS': [29, 6, 11, 21], 'DOUAI': [38, 14, 16, 22], 'PARIS NORD': [29, 14, 17, 21], 'MACON LOCHE': [74, 12, 9, 31], 'MARNE LA VALLEE': [63, 10, 19, 36], 'PERPIGNAN': [36, 11, 16, 47], 'TOULON': [43, 11, 14, 40], 'METZ': [45, 7, 11, 24], 'NANCY': [36, 7, 7, 30], 'GRENOBLE': [10, 40, 13, 37], 'NIMES': [54, 12, 15, 34], 'ANGOULEME': [54, 7, 11, 29], 'VANNES': [51, 6, 13, 31], 'MARSEILLE ST CHARLES': [27, 11, 15, 39], 'ANNECY': [7, 18, 13, 40], 'AVIGNON TGV': [46, 9, 13, 35], 'LAVAL': [40, 7, 12, 22], 'LE MANS': [55, 7, 12, 20], 'ST MALO': [31, 7, 9, 31], 'ARRAS': [46, 8, 12, 23], 'AIX EN PROVENCE TGV': [54, 8, 11, 43], 'DIJON VILLE': [56, 7, 8, 34], 'BELLEGARDE': [51, 6, 17, 30], 'ANGERS ST LAUD': [54, 7, 12, 26], 'BESANCON TGV': [33, 7, 9, 32], 'ST ETIENNE CHATEAUCREUX': [25, 21, 12, 27], 'VALENCE TGV': [63, 12, 12, 34], 'LE CREUSOT MONTCEAU': [60, 7, 11, 22], 'PARIS MONTPARNASSE VAUGIRARD': [15, 16, 13, 40]} 51\n",
      "dict_keys(['BORDEAUX ST JEAN', 'LA ROCHELLE VILLE', 'PARIS MONTPARNASSE', 'QUIMPER', 'RENNES', 'ST PIERRE DES CORPS', 'TOURS', 'NANTES', 'PARIS EST', 'STRASBOURG', 'DUNKERQUE', 'LILLE', 'TOURCOING', 'CHAMBERY CHALLES LES EAUX', 'LYON PART DIEU', 'MONTPELLIER', 'MULHOUSE VILLE', 'NICE VILLE', 'PARIS LYON', 'BREST', 'POITIERS', 'TOULOUSE MATABIAU', 'REIMS', 'DOUAI', 'PARIS NORD', 'MACON LOCHE', 'MARNE LA VALLEE', 'PERPIGNAN', 'TOULON', 'METZ', 'NANCY', 'GRENOBLE', 'NIMES', 'ANGOULEME', 'VANNES', 'MARSEILLE ST CHARLES', 'ANNECY', 'AVIGNON TGV', 'LAVAL', 'LE MANS', 'ST MALO', 'ARRAS', 'AIX EN PROVENCE TGV', 'DIJON VILLE', 'BELLEGARDE', 'ANGERS ST LAUD', 'BESANCON TGV', 'ST ETIENNE CHATEAUCREUX', 'VALENCE TGV', 'LE CREUSOT MONTCEAU', 'PARIS MONTPARNASSE VAUGIRARD'])\n"
     ]
    }
   ],
   "source": [
    "def create_dict_tgv():\n",
    "    df = pd.read_csv('./dataset/regularite-mensuelle-tgv-aqst.csv',sep=\";\")\n",
    "    list_station = create_list_station()\n",
    "    dict_tgv = {}\n",
    "\n",
    "    for x in df.index:\n",
    "        gare = df[\"Gare de départ\"][x]\n",
    "        if (gare in list_station):\n",
    "            if(gare in dict_tgv):\n",
    "                dict_tgv[gare][0] += df[\"Nombre de circulations prévues\"][x]\n",
    "                dict_tgv[gare][1] += df[\"Nombre de trains en retard au départ\"][x]\n",
    "                dict_tgv[gare][2] += 1\n",
    "                dict_tgv[gare][3] += df[\"Retard moyen des trains en retard au départ\"][x]\n",
    "                \n",
    "            else:\n",
    "                value = [df[\"Nombre de circulations prévues\"][x] , df[\"Nombre de trains en retard au départ\"][x], 1, df[\"Retard moyen des trains en retard au départ\"][x]]\n",
    "                dict_tgv[gare] = value\n",
    "\n",
    "    for x in dict_tgv:\n",
    "        dict_tgv[x][0] = round((dict_tgv[x][1]/dict_tgv[x][0])*100)\n",
    "        dict_tgv[x][1] = round(dict_tgv[x][3]/dict_tgv[x][2])\n",
    "        dict_tgv[x].pop(2)\n",
    "        dict_tgv[x].pop(2)\n",
    "\n",
    "\n",
    "    for x in df.index:\n",
    "        gare = df[\"Gare d'arrivée\"][x]\n",
    "        if (gare in list_station ):\n",
    "            if(gare in dict_tgv and len(dict_tgv[gare]) > 2):\n",
    "                dict_tgv[gare][2] += df[\"Nombre de circulations prévues\"][x]\n",
    "                dict_tgv[gare][3] += df[\"Nombre de trains en retard à l'arrivée\"][x]\n",
    "                dict_tgv[gare][4] += 1\n",
    "                dict_tgv[gare][5] += df[\"Retard moyen des trains en retard à l'arrivée\"][x]\n",
    "                \n",
    "            else:\n",
    "                dict_tgv[gare].append(df[\"Nombre de circulations prévues\"][x])\n",
    "                dict_tgv[gare].append(df[\"Nombre de trains en retard à l'arrivée\"][x])\n",
    "                dict_tgv[gare].append(1)\n",
    "                dict_tgv[gare].append(df[\"Retard moyen des trains en retard à l'arrivée\"][x])\n",
    "\n",
    "\n",
    "    for x in dict_tgv:\n",
    "        dict_tgv[x][2] = round((dict_tgv[x][3]/dict_tgv[x][2])*100)\n",
    "        dict_tgv[x][3] = round(dict_tgv[x][5]/dict_tgv[x][4])\n",
    "        dict_tgv[x].pop(4)\n",
    "        dict_tgv[x].pop(4)\n",
    "\n",
    "    dict_tgv[\"BELLEGARDE\"] = dict_tgv.pop(\"BELLEGARDE (AIN)\")\n",
    "    dict_tgv[\"ANGERS ST LAUD\"] = dict_tgv.pop(\"ANGERS SAINT LAUD\")\n",
    "    dict_tgv[\"BESANCON TGV\"] = dict_tgv.pop(\"BESANCON FRANCHE COMTE TGV\")\n",
    "    dict_tgv[\"ST ETIENNE CHATEAUCREUX\"] = dict_tgv.pop(\"SAINT ETIENNE CHATEAUCREUX\")\n",
    "    dict_tgv[\"VALENCE TGV\"] = dict_tgv.pop(\"VALENCE ALIXAN TGV\")\n",
    "    dict_tgv[\"LE CREUSOT MONTCEAU\"] = dict_tgv.pop(\"LE CREUSOT MONTCEAU MONTCHANIN\")\n",
    "    dict_tgv[\"PARIS MONTPARNASSE VAUGIRARD\"] = dict_tgv.pop(\"PARIS VAUGIRARD\")\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    return dict_tgv\n",
    "\n",
    "dict_tgv = create_dict_tgv()\n",
    "\n",
    "print(dict_tgv,len(dict_tgv))\n",
    "\n",
    "print(dict_tgv.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BORDEAUX ST JEAN': [36, 11, 10, 34, 44.825873, -0.556697], 'LA ROCHELLE VILLE': [18, 8, 8, 34, 46.15269, -1.145305], 'PARIS MONTPARNASSE': [27, 10, 15, 29, 48.841172, 2.320514], 'QUIMPER': [20, 20, 9, 42, 47.994455, -4.092103], 'RENNES': [42, 11, 11, 35, 46.3154922, 3.3941783], 'ST PIERRE DES CORPS': [47, 6, 12, 20, 47.386099, 0.72355], 'TOURS': [18, 6, 14, 19, 47.3541741, 0.6675586], 'NANTES': [34, 12, 11, 38, 47.216148, -1.542356], 'PARIS EST': [32, 10, 14, 28, 48.876742, 2.358424], 'STRASBOURG': [51, 7, 8, 39, 48.5632897, 7.6950455], 'DUNKERQUE': [4, 12, 11, 34, 51.03047, 2.368961], 'LILLE': [36, 8, 17, 33, 50.6119054, 3.075837], 'TOURCOING': [15, 14, 15, 40, 50.71683, 3.16804], 'CHAMBERY CHALLES LES EAUX': [64, 12, 15, 35, 45.571302, 5.919547], 'LYON PART DIEU': [58, 9, 13, 35, 45.760559, 4.859355], 'MONTPELLIER': [46, 11, 15, 38, 43.604738, 3.880674], 'MULHOUSE VILLE': [50, 6, 11, 37, 47.742224, 7.342396], 'NICE VILLE': [31, 9, 13, 48, 43.704556, 7.261904], 'PARIS LYON': [19, 14, 14, 37, 48.844888, 2.37352], 'BREST': [19, 16, 8, 44, 48.38811, -4.478903], 'POITIERS': [40, 9, 10, 25, 46.582275, 0.333241], 'TOULOUSE MATABIAU': [22, 15, 13, 47, 43.611206, 1.453616], 'REIMS': [29, 6, 11, 21, 49.2336853, 4.0224927], 'DOUAI': [38, 14, 16, 22, 50.6119054, 3.075837], 'PARIS NORD': [29, 14, 17, 21, 48.880185, 2.355151], 'MACON LOCHE': [74, 12, 9, 31, 46.282884, 4.778876], 'MARNE LA VALLEE': [63, 10, 19, 36, 48.869856, 2.78272], 'PERPIGNAN': [36, 11, 16, 47, 42.696292, 2.879779], 'TOULON': [43, 11, 14, 40, 43.12837, 5.929293], 'METZ': [45, 7, 11, 24, 49.109545, 6.176593], 'NANCY': [36, 7, 7, 30, 48.689861, 6.174583], 'GRENOBLE': [10, 40, 13, 37, 45.184877, 5.78474], 'NIMES': [54, 12, 15, 34, 43.832291, 4.365845], 'ANGOULEME': [54, 7, 11, 29, 45.653572, 0.164608], 'VANNES': [51, 6, 13, 31, 47.665169, -2.75245], 'MARSEILLE ST CHARLES': [27, 11, 15, 39, 43.302666, 5.380407], 'ANNECY': [7, 18, 13, 40, 45.901965, 6.121835], 'AVIGNON TGV': [46, 9, 13, 35, 43.921586, 4.786079], 'LAVAL': [40, 7, 12, 22, 45.7878115, 4.7309383], 'LE MANS': [55, 7, 12, 20, 47.995689, 0.192578], 'ST MALO': [31, 7, 9, 31, 48.646859, -2.004158], 'ARRAS': [46, 8, 12, 23, 50.286673, 2.781942], 'AIX EN PROVENCE TGV': [54, 8, 11, 43, 43.455237, 5.317534], 'DIJON VILLE': [56, 7, 8, 34, 47.32337, 5.027208], 'BELLEGARDE': [51, 6, 17, 30, 46.109425, 5.823483], 'ANGERS ST LAUD': [54, 7, 12, 26, 47.464647, -0.55682], 'BESANCON TGV': [33, 7, 9, 32, 47.307361058531725, 5.953195095062256], 'ST ETIENNE CHATEAUCREUX': [25, 21, 12, 27, 45.443366, 4.399722], 'VALENCE TGV': [63, 12, 12, 34, 44.991545, 4.978703], 'LE CREUSOT MONTCEAU': [60, 7, 11, 22, 46.765343, 4.499513], 'PARIS MONTPARNASSE VAUGIRARD': [15, 16, 13, 40, 48.841172, 2.320514]} 51\n"
     ]
    }
   ],
   "source": [
    "def complete_dict_tgv():\n",
    "    df = pd.read_csv('./dataset/referentiel-gares-voyageurs.csv',sep=\";\")\n",
    "    dict_tgv = create_dict_tgv()\n",
    "    lis = []\n",
    "\n",
    "    for gare in dict_tgv:\n",
    "        for x in df.index:\n",
    "            if type(df[\"RG\"][x]) == str and ((gare in df[\"RG\"][x]) or gare in df[\"Intitulé plateforme\"][x].upper()) and gare not in lis:\n",
    "                lis.append(gare)\n",
    "                dict_tgv[gare].append(df[\"Latitude\"][x])\n",
    "                dict_tgv[gare].append(df[\"Longitude\"][x])\n",
    "\n",
    "\n",
    "    return dict_tgv\n",
    "dict_tgv = complete_dict_tgv()\n",
    "print(dict_tgv, len(dict_tgv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map_retard_tgv(dict_tgv):\n",
    "    \n",
    "    m = folium.Map(\n",
    "            location=[45.90, 6.09],\n",
    "            zoom_start=7,\n",
    "        )\n",
    "    for x in dict_tgv:\n",
    "        text = \"<center><b>\" + str(x) + \"</b><br/><br/>Trains en retard au départ : <b>\" + str(dict_tgv[x][0]) + \"%</b><br/>Moyenne des retards au départ : <b>\" + str(dict_tgv[x][1]) + \" min</b><br/>Trains en retard à l'arrivée : <b>\" + str(dict_tgv[x][2]) + \"%</b><br/>Moyenne des retards à l'arrivée : <b>\" + str(dict_tgv[x][3]) + \" min</b></center><br/>\"\n",
    "        folium.Circle(\n",
    "            radius=500,\n",
    "            location=[dict_tgv[x][4], dict_tgv[x][5]],\n",
    "            popup = folium.Popup(text, parse_html=False, min_width=300, max_width=300),\n",
    "            color = \"red\",\n",
    "            fill=True,\n",
    "        ).add_to(m)\n",
    "\n",
    "\n",
    "    m.save(\"stations_tgv_retard.html\")\n",
    "\n",
    "create_map_retard_tgv(dict_tgv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Grand Est': [38841, 927, 95], 'Normandie': [10215, 159, 93], 'Centre Val-de-Loire': [10143, 163, 91], 'Hauts-de-France': [26962, 1322, 89], 'Bretagne': [9008, 100, 96], 'Auvergne-Rhône-Alpes': [36455, 718, 92], 'Bourgogne-Franche-Comté': [14903, 193, 94], 'Occitanie': [12319, 480, 89], 'Nouvelle Aquitaine': [16560, 419, 91], 'Pays-de-la-Loire': [13490, 204, 94], \"Provence Alpes Côte d'Azur\": [13246, 313, 90]} 11\n"
     ]
    }
   ],
   "source": [
    "def create_dict_ter():\n",
    "    df = pd.read_csv('./dataset/regularite-mensuelle-ter.csv',sep=\";\")\n",
    "    dict_regions = {}\n",
    "\n",
    "    for x in df.index:\n",
    "        region = df[\"Région\"][x]\n",
    "    \n",
    "        if (\"2022\" in df[\"Date\"][x]):\n",
    "            if(region in dict_regions):\n",
    "\n",
    "                dict_regions[region][0] += df[\"Nombre de trains ayant circulé\"][x]\n",
    "                dict_regions[region][1] += df[\"Nombre de trains annulés\"][x]\n",
    "                dict_regions[region][2] += df[\"Taux de régularité\"][x]\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                value = [df[\"Nombre de trains ayant circulé\"][x] , df[\"Nombre de trains annulés\"][x],df[\"Taux de régularité\"][x]]\n",
    "                dict_regions[region] = value\n",
    "\n",
    "    for x in dict_regions:\n",
    "        for y in range(len(dict_regions[x])):\n",
    "            # print(x)\n",
    "            # print(y)\n",
    "            dict_regions[x][y] = round(dict_regions[x][y] / 11)\n",
    "\n",
    "    return dict_regions\n",
    "\n",
    "dict_ter = create_dict_ter()\n",
    "print(create_dict_ter(), len(create_dict_ter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_map_retard_ter(dict_ter):\n",
    "    \n",
    "    # Charger les données GeoJSON des régions françaises\n",
    "    regions = gpd.read_file(\"./dataset/regions.json\")\n",
    "    # print(regions[\"nom\"])\n",
    "\n",
    "\n",
    "    # Créer une carte de France centrée sur les coordonnées [46.2276, 2.2137]\n",
    "    france_map = folium.Map(location=[46.2276, 2.2137], zoom_start=6)\n",
    "    \n",
    "\n",
    "    # Ajouter les régions sur la carte\n",
    "    for i in range(len(regions)):\n",
    "        \n",
    "        region = regions.iloc[i]\n",
    "        if (region[\"nom\"] != \"Île-de-France\" and region[\"nom\"] != \"Corse\"):\n",
    "            text = \"<center><b>\" +region[\"nom\"] + \"</b><br/><br/>Moyenne mensuelle des trains ayant circulé : <b>\" + str(dict_ter[region[\"nom\"]][0]) + \"</b><br/>Moyenne mensuelle des trains annulés : <b>\" + str(dict_ter[region[\"nom\"]][1]) + \"</b><br/>Taux de régularité des trains : <b>\" + str(dict_ter[region[\"nom\"]][2]) + \"%</b></center><br/>\"\n",
    "            geometry = region[\"geometry\"]\n",
    "            folium.GeoJson(geometry).add_child(folium.Popup(text, parse_html=False, min_width=300, max_width=300)).add_to(france_map)\n",
    "\n",
    "    # Afficher la carte\n",
    "    france_map.save(\"regions_ter_retard.html\")\n",
    "\n",
    "create_map_retard_ter(dict_ter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map_retard(dict_tgv, dict_ter):\n",
    "    # style_red = {'fillColor': '#FF0000', 'color': '#FF0000'} #RED\n",
    "    # style_green = {'fillColor': '#00FF00', 'color': '#00FF00'} #GREEN\n",
    "    # style_orange = {'fillColor': '#FFA500', 'color': '#FFA500'} #ORANGE\n",
    "    # # Charger les données GeoJSON des régions françaises\n",
    "    regions = gpd.read_file(\"./dataset/regions.json\")\n",
    "    # print(regions[\"nom\"])\n",
    "\n",
    "\n",
    "    # Créer une carte de France centrée sur les coordonnées [46.2276, 2.2137]\n",
    "    france_map = folium.Map(location=[46.2276, 2.2137], zoom_start=6)\n",
    "    \n",
    "\n",
    "    # Ajouter les régions sur la carte\n",
    "    for i in range(len(regions)):\n",
    "        \n",
    "        region = regions.iloc[i]\n",
    "        \n",
    "        if (region[\"nom\"] != \"Île-de-France\" and region[\"nom\"] != \"Corse\"):\n",
    "            # style_color = {'fillColor': '#FFA500', 'color': '#FFA500'}\n",
    "            text = \"<center><b>\" +region[\"nom\"] + \"</b><br/><br/>Moyenne mensuelle des TER ayant circulé : <b>\" + str(dict_ter[region[\"nom\"]][0]) + \"</b><br/>Moyenne mensuelle des TER annulés : <b>\" + str(dict_ter[region[\"nom\"]][1]) + \"</b><br/>Moyenne mensuelle de la proportion des TER arrivant à l'heure : <b>\" + str(dict_ter[region[\"nom\"]][2]) + \"%</b></center><br/>\"\n",
    "            geometry = region[\"geometry\"]\n",
    "            # if dict_ter[region[\"nom\"]][2] <= 91:\n",
    "            #     style_color = {'fillColor': '#FF0000', 'color': '#FF0000'}\n",
    "            # elif dict_ter[region[\"nom\"]][2] > 94:\n",
    "            #     style_color = {'fillColor': '#00FF00', 'color': '#00FF00'}\n",
    "            # else:\n",
    "            #     style_color = {'fillColor': '#FFA500', 'color': '#FFA500'}\n",
    "\n",
    "            \n",
    "            # n=folium.GeoJson(geometry, style_function=lambda x:style_color)\n",
    "            folium.GeoJson(geometry).add_child(folium.Popup(text, parse_html=False, min_width=300, max_width=300)).add_to(france_map)\n",
    "\n",
    "    for x in dict_tgv:\n",
    "        text = \"<center><b>\" + str(x) + \"</b><br/><br/>TGV en retard au départ : <b>\" + str(dict_tgv[x][0]) + \"%</b><br/>Moyenne des retards TGV au départ : <b>\" + str(dict_tgv[x][1]) + \" min</b><br/>TGV en retard à l'arrivée : <b>\" + str(dict_tgv[x][2]) + \"%</b><br/>Moyenne des retards TGV à l'arrivée : <b>\" + str(dict_tgv[x][3]) + \" min</b></center><br/>\"\n",
    "        folium.Circle(\n",
    "            radius=500,\n",
    "            location=[dict_tgv[x][4], dict_tgv[x][5]],\n",
    "            popup = folium.Popup(text, parse_html=False, min_width=300, max_width=300),\n",
    "            color = \"red\",\n",
    "            fill=True,\n",
    "        ).add_to(france_map)\n",
    "\n",
    "\n",
    "    france_map.save(\"carte_retard.html\")\n",
    "    \n",
    "create_map_retard(dict_tgv, dict_ter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54028329828d624b463ded62151743d5daf48de4f0c6e4871a15710cfc76018c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
